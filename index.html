

<!DOCTYPE html>
<!--
Resume
-->
<html xmlns="http://www.w3.org/1999/xhtml"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Zehui Liao</title>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css">
	<script type="text/javascript" src="//clustrmaps.com/map_v2.js?d=3oEqJsYfiOcdbboZSNw7vF51Tg07i-AMnmtYt_vxKlU&cl=ffffff&w=a"></script>
<style type="text/css">
 /*@import url("http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600,600italic");*/


body
{
	font-family: 'Source Sans Pro', sans-serif;
    background-color : #CDCDCD;
    font-size: 17px;
}
    .content
	{
    		width : 1200px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		background-color : #fff;
    		box-shadow: 0px 0px 10px #999;
    		border-radius: 15px;
	}
	table
	{
		padding: 5px;
	}

	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 1000px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }

	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 1000px;
		text-align: justify;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #3B3B3B;
		height: 158px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #5B5B5B;
		margin-bottom: 50px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}

    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px;
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
    }
</style>
</head>


<body>
<div class="content">
	<div id="container">
<center>
	<table>
	<tbody><tr>
	<td><img id="myPicture" src="images/id.png" style="float:left; padding-right:10px" height="200px"></td>
	<td>
	<div id="DocInfo">
		<h1><strong>Zehui Liao</strong></h1>
						<h2>Ph.D. Candidate</h2>
							Affiliation: School of Computer Science and Engineering, Northwestern Polytechnical University<br />
							Current Address: No.1, Dongxiang Road, Chang'an District, Xi'an, Shaanxi, China<br />
							Email: merrical@mail.nwpu.edu.cn<br />
							<a href="https://scholar.google.com/citations?user=xdYS1e0AAAAJ&hl=zh-CN">Google Scholar</a>
							&bull; <a href="https://www.semanticscholar.org/author/Zehui-Liao/2028786413">Semantic Scholar</a>
							&bull; <a href="https://github.com/Merrical">GitHub</a>
						</div><br>
	</td>
	</tr>
	</tbody></table>
</center>
<br>
	<h2><strong>Biography</strong></h2>
	<ul>
		<li><strong>Introduction</strong></li>
			<ul>
			I am a fourth-year Ph.D. student at National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University (NPU), China.
			My research focuses on deep learning techniques for medical image analysis, with particular interests in hallucination detection in medical MLLMs, learning with label noise, and domain adaptation.

			</ul>
		<li><strong>Education Background</strong></li>
			<ul>
			<li>2020.09-Present &nbsp; &bull;&nbsp;&nbsp; Ph.D. Candidate &nbsp;  &nbsp;&bull;&nbsp; Supervisor: <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.<br></li>
			<h6>School of Computer Science and Technology, Northwestern Polytechnical University, China</h6>
			<li>2016.09-2020.06 &nbsp; &bull;&nbsp; B.E. Degree &nbsp; &bull;&nbsp; Supervisor: <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.<br></li>
			<h6>School of Computer Science and Technology, Northwestern Polytechnical University, China</h6>
			</ul>
<!--		<li><strong>Internship Experience</strong></li>-->
<!--			<ul>-->
<!--			<li></li>-->
<!--			</ul>-->
	</ul>
    <h2><strong>News</strong></h2>
	<div style="height: 230px; overflow: auto;">
		<li>[2025.08.10] One paper was accepted by PR, about <a href="https://arxiv.org/pdf/2211.11514.pdf">Source-Free Domain Adaptation</a>.</li>
		<li>[2025.06.18] Two papers were accepted by MICCAI 2025, about <a href="https://arxiv.org/abs/2503.20504">Hallucination Detection in Medical MLLMs</a> and <a>In-Context Medical Image Segmentation</a>.</li>
		<li>[2025.06.15] One paper was accepted by MedIA, about <a href="https://arxiv.org/abs/2406.12293">Learning with Label Noise</a>.</li>
		<li>[2024.11.04] One paper was accepted by IJCV, about <a href="https://arxiv.org/abs/2212.08380">Learning with Label Noise</a>.</li>
		<li>[2023.08.02] One paper was accepted by MedIA, about <a href="https://arxiv.org/abs/2111.13410">Learning with Multiple Annotators</a>.</li>
    	<li>[2023.08.02] One paper was accepted by DALI@MICCAI 2023, about <a href="https://arxiv.org/abs/2308.08772">Noisy Label Learning</a>.</li>
		<li>[2023.05.25] Two papers were early accepted by MICCAI 2023, about <a href="https://arxiv.org/abs/2306.01340">Learning with Multiple Annotators</a> and <a href="https://arxiv.org/abs/2306.05254">Domain Generalization</a>.</li>
		<li>[2022.09.22] One journal paper was accepted by IEEE TMI, about <a href="https://arxiv.org/pdf/2109.05676.pdf">Domain Generalization</a>.</li>
		<li>[2022.08.29] Our <a href="https://arxiv.org/abs/2208.13337">Label Propagation Framework</a> got the 2-nd place of <a href="https://vessel-wall-segmentation-2022.grand-challenge.org/results/">CarOtid vessel wall SegMentation and atherosclerOsis diagnosiS challenge</a>.[<a href="https://github.com/ShishuaiHu/Label-Propagation">Code</a>, <a href="https://github.com/ShishuaiHu/Label-Propagation/releases/tag/public">Pretrained Model</a>]</li>
		<li>[2022.08.21] Our <a href="https://arxiv.org/abs/2208.13774">Boundary-Aware Network</a> got the Top-5 of <a href="https://amos22.grand-challenge.org/final-ranking/">Multi-Modality Abdominal Multi-Organ Segmentation Challenge 2022</a>.[<a href="https://github.com/ShishuaiHu/BA-Net/tree/amos22">Code</a>, <a href="https://zenodo.org/record/7030453">Pretrained Model</a>]</li>
		<li>[2022.08.17] Our <a href="https://arxiv.org/abs/2208.13338">Boundary-Aware Network</a> won the 2-nd place of <a href="https://kipa22.grand-challenge.org/evaluation/open-evaluation/leaderboard/">Kidney PArsing Challenge 2022</a>.[<a href="https://github.com/ShishuaiHu/BA-Net/tree/kipa22">Code</a>, <a href="https://zenodo.org/record/7030423">Pretrained Model</a>]</li>
		<li>[2022.06.03] One paper was accepted by MICCAI 2022, about <a href="https://github.com/ShishuaiHu/DoCR/raw/master/pdf/MICCAI-DoCR.pdf">Unsupervised Domain Adaptation</a>.</li>
		<li>[2022.02.02] One journal paper was accepted by IEEE TMI, about <a href="https://arxiv.org/pdf/2104.11436">Noisy Label Learning</a>.</li>
		<li>[2020.07.10] I received the B.E. degree from Northwestern Polytechnical University, supervised by <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.</li>
    	</ul>
	</div>
	<br>
	<h2><strong>Representative Publications </strong></h2>
	<ul>
		* indicates corresponding authorship and <sup>†</sup> indicates equal contribution.
	</ul>

	<h5><strong>Hallucination Detection in Medical MLLMs</strong></h5>
	<table class="pub_table" >
		<tbody>
			<tr>
				<td class="pub_td1"><img src="images/2026-VLoop.png" class="papericon"></td>
				<td class="pub_td2">Mengyuan Jin<sup>†</sup>, <u>Zehui Liao</u><sup>†</sup>, and Yong Xia*<br><b>
					V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering</b><br> arXiv preprint arXiv:2601.18240. [<a href="https://arxiv.org/pdf/2601.18240">Paper</a>] 
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/2026-UniVRSE.png" class="papericon"></td>
				<td class="pub_td2"><u>Zehui Liao</u><sup>†</sup>, Shishuai Hu, Ke Zou, Mengyuan Jin, Yanning Zhang, Huazhu Fu, Liangli Zhen*, and Yong Xia*<br><b>
					UniVRSE: Unified Vision-conditioned Response Semantic Entropy for Hallucination Detection in Medical Vision-Language Models</b><br> arXiv preprint arXiv:2503.20504. [<a href="https://arxiv.org/pdf/2503.20504">Paper</a>, <a href="https://github.com/Merrical/VASE">Code</a>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/2025-VASE.png" class="papericon"></td>
				<td class="pub_td2"><u>Zehui Liao</u><sup>†</sup>, Shishuai Hu<sup>†</sup>, Ke Zou, Huazhu Fu, Liangli Zhen*, and Yong Xia*<br><b>
					Vision-Amplified Semantic Entropy for Hallucination Detection in Medical Visual Question Answering</b><br> MICCAI 2025. [<a href="https://link.springer.com/chapter/10.1007/978-3-032-04971-1_63">Paper</a>, <a href="https://github.com/Merrical/VASE">Code</a>]
			</td></tr>
		</tbody>
	</table>

	<h5><strong>Learning with Label Noise for Medical Image Analysis</strong></h5>
	<table class="pub_table" >
		<tbody>
			<tr>
				<td class="pub_td1"><img src="images/2025-ENCOFA.png" class="papericon"></td>
				<td class="pub_td2"><u>Zehui Liao</u>, Shishuai Hu, Yanning Zhang, and Yong Xia*<br><b>
					Unleashing the Potential of Open-set Noisy Samples Against Label Noise for Medical Image Classification</b><br> Medical Image Analysis, 2025. [<a href="https://arxiv.org/abs/2406.12293">Paper</a>, <a href="https://github.com/Merrical/ENCOFA">Code</a>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/2024-ILDE.png" class="papericon"></td>
				<td class="pub_td2"><u>Zehui Liao</u>, Shishuai Hu, Yutong Xie, and Yong Xia*<br><b>
					Instance-dependent Label Distribution Estimation for Learning with Label Noise</b><br> International Journal of Computer Vision, 2024. [<a href="https://arxiv.org/pdf/2212.08380.pdf">Paper</a>, <a href="https://github.com/Merrical/ILDE">Code</a>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/2021-PADL.png" class="papericon"></td>
				<td class="pub_td2"><u>Zehui Liao</u><sup>†</sup>, Shishuai Hu<sup>†</sup>, Yutong Xie, and Yong Xia*<br><b>
					Modeling Annotator Preference and Stochastic Annotation Error for Medical Image Segmentation</b><br> Medical Image Analysis, In Press, 2023. [<a href="https://arxiv.org/pdf/2111.13410.pdf">Paper</a>, <a href="https://github.com/Merrical/PADL">Code</a>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/2023-URL.png" class="papericon"></td>
				<td class="pub_td2">Xianze Ai<sup>†</sup>, <u>Zehui Liao</u><sup>†</sup>, and Yong Xia*<br><b>
					URL: Combating Label Noise for Lung Nodule Malignancy Grading</b><br> The 3rd MICCAI Workshop on Data Augmentation, Labeling, and Imperfections (DALI), 2023. [<a href="https://arxiv.org/pdf/2308.08772.pdf">Paper</a>, <a href="https://github.com/axz520/URL">Code</a>][<FONT COLOR="#ff0000">Oral</FONT>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/2023-TAB.png" class="papericon"></td>
				<td class="pub_td2"><u>Zehui Liao</u>, Shishuai Hu, Yutong Xie*, and Yong Xia*<br><b>
					Transformer-based Annotation Bias-aware Medical Image Segmentation</b><br> MICCAI, 2023. [<a href="https://arxiv.org/pdf/2306.01340.pdf">Paper</a>, <a href="https://github.com/Merrical/TAB">Code</a>][<FONT COLOR="#ff0000">Early Accept</FONT>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/2022-MV-DAR.png" class="papericon"></td>
				<td class="pub_td2"><u>Zehui Liao</u><sup>†</sup>, Yutong Xie<sup>†</sup>, Shishuai Hu, and Yong Xia*<br><b>
					Learning from Ambiguous Labels for Lung Nodule Malignancy Prediction</b><br> IEEE Transactions on Medical Imaging, vol. 41, pp. 1874-1884, 2022. [<a href="https://arxiv.org/pdf/2104.11436">Paper</a>, <a href="https://github.com/Merrical/DAR">Code</a>]
			</td></tr>
		</tbody></table>
	
	<h5><strong>In-Context Medical Image Segmentation</strong></h5>
	<table class="pub_table" >
	<tbody>
		<tr>
			<td class="pub_td1"><img src="images/2025-CCV.png" class="papericon"></td>
			<td class="pub_td2">Shishuai Hu<sup>†</sup>, <u>Zehui Liao</u><sup>†</sup>, Liangli Zhen, Huazhu Fu*, and Yong Xia*<br><b>
				Cycle Context Verification for In-Context Medical Image Segmentation</b><br> MICCAI 2025. [<a href="https://github.com/ShishuaiHu/CCV">Code</a>]
		 </td></tr>
	</tbody></table>

	<h5><strong>Domain Adaptive Medical Image Segmentation</strong></h5>
	<table class="pub_table" >
	<tbody>
		<tr>
			<td class="pub_td1"><img src="images/2023-CSDG.png" class="papericon"></td>
			<td class="pub_td2">Shishuai Hu, <u>Zehui Liao</u>, and Yong Xia*<br><b>
				Devil is in Channels: Contrastive Single Domain Generalization for Medical Image Segmentation</b><br> MICCAI, 2023. [<a href="https://arxiv.org/abs/2306.05254.pdf">Paper</a>, <a href="https://github.com/ShishuaiHu/CCSDG">Code</a>][<FONT COLOR="#ff0000">Early Accept</FONT>]
		 </td></tr>
		<tr>
			<td class="pub_td1"><img src="images/2022-ProSFDA.png" class="papericon"></td>
			<td class="pub_td2">Shishuai Hu, <u>Zehui Liao</u>, and Yong Xia*<br><b>
				Prompt Learning based Source-free Domain Adaptation for Medical Image Segmentation</b><br> Pattern Recognition, 2025. [<a href="https://arxiv.org/pdf/2211.11514.pdf">Paper</a>, <a href="https://github.com/ShishuaiHu/ProSFDA">Code</a>]
		 </td></tr>
		<tr>
			<td class="pub_td1"><img src="images/2022-DoCR.png" class="papericon"></td>
			<td class="pub_td2">Shishuai Hu<sup>†</sup>, <u>Zehui Liao</u><sup>†</sup>, and Yong Xia*<br><b>
				Domain Specific Convolution and High Frequency Reconstruction based Unsupervised Domain Adaptation for Medical Image Segmentation</b><br> MICCAI 2022, In Press, 2022. [<a href="https://github.com/ShishuaiHu/DoCR/raw/master/pdf/MICCAI-DoCR.pdf">Paper</a>, <a href="https://github.com/ShishuaiHu/DoCR">Code</a>]
		 </td></tr>
		<tr>
			<td class="pub_td1"><img src="images/2021-DCAC.png" class="papericon"></td>
			<td class="pub_td2">Shishuai Hu<sup>†</sup>, <u>Zehui Liao</u><sup>†</sup>, Jianpeng Zhang, and Yong Xia*<br><b>
				Domain and Content Adaptive Convolution based Multi-Source Domain Generalization for Medical Image Segmentation</b><br> IEEE Transactions on Medical Imaging, vol. 42, pp. 233-244, 2023. [<a href="https://arxiv.org/pdf/2109.05676.pdf">Paper</a>, <a href="https://github.com/ShishuaiHu/DCAC">Code</a>, <a href="https://shishuaihu.github.io/DCAC/">Project</a>]
		 </td></tr>

	</tbody></table>

	<h5><strong>Volumetric Medical Image Segmentation</strong></h5>
	<table class="pub_table" >
	<tbody>
		<tr>
			<td class="pub_td1"><img src="images/2023-BA-Net.png" class="papericon"></td>
			<td class="pub_td2">Shishuai Hu, <u>Zehui Liao</u>, Yiwen Ye, and Yong Xia*<br><b>
				Boundary-Aware Network for Kidney Parsing</b><br> MICCAI 2022 Workshop, Lesion Segmentation in Surgical and Diagnostic Applications, 2023. [<a href="https://link.springer.com/chapter/10.1007/978-3-031-27324-7_2">Paper</a>, <a href="https://github.com/ShishuaiHu/BA-Net">Code</a>, <a href="https://shishuaihu.github.io/BA-Net/">Project</a>] [<FONT COLOR="#ff0000">Rank 2-nd in KiPA22, Rank Top-5 in AMOS22</FONT>]
		 </td></tr>
	</tbody></table>

	<h2><strong>Patents</strong></h2>
        <ul>
			<li>Yong Xia, <u>Zehui Liao</u>, and Yutong Xie. A Medical Image Classification Method for Learning with Ambiguously-labeled Data. Chinese Patent ZL202110203910.X, issued on 2022/11/29.</li>
			<li>Yong Xia, <u>Zehui Liao</u>, and Yutong Xie. A Self-supervised Pretraining Method for Downstream 3D Medical Image Segmentation Tasks. ZL 2021 1 1523320.1, issued on 2024/3/15.</li>
		</ul>

    <h2><strong>Awards and Honors</strong></h2>
        <ul>
			<li>[2024.11]  &nbsp;&bull;&nbsp; National Scholarship for PhD Students  </li>
			<li>[2023.10]  &nbsp;&bull;&nbsp; Outstanding Graduate Student of Northwestern Polytechnical University  </li>
			<li>[2022.10]  &nbsp;&bull;&nbsp; First-class Academic Scholarship for Doctoral Students  </li>
			<li>[2022.09]  &nbsp;&bull;&nbsp; Innovation Award in Kidney Parsing Challenge </li>
			<li>[2022.08]  &nbsp;&bull;&nbsp; Second Place in CarOtid vessel wall SegMentation and atherosclerOsis diagnosiS (COSMOS) Challenge </li>
			<li>[2022.08]  &nbsp;&bull;&nbsp; Top-5 in Multi-Modality Abdominal Multi-Organ Segmentation (AMOS) Challenge </li>
			<li>[2022.08]  &nbsp;&bull;&nbsp; Second Place in Kidney Parsing Challenge </li>
            <li>[2022.08]  &nbsp;&bull;&nbsp; Second Prize in MICS Student Presentation Challenge</li>
			<li>[2022.09]  &nbsp;&bull;&nbsp; University Graduate Fellowship, Northwestern Polytechnical University</li>
			<li>[2020.09]  &nbsp;&bull;&nbsp; University Graduate Fellowship, Northwestern Polytechnical University</li>
			<li>[2019.08]  &nbsp;&bull;&nbsp; First Place in Pro. SimuroSot-Miro Middle at 24th FIRA RobotWorld Cup 2019</li>
			<li>[2019.08]  &nbsp;&bull;&nbsp; First Place in Pro. Air Autonomous Race Pro at 24th FIRA RobotWorld Cup 2019</li>
			<li>[2018.10]  &nbsp;&bull;&nbsp; First Place in Pro. Microsoft Wheeled-SimuroSot (11 vs. 11) at 20th China Robotics and Artificial Intelligence Competition 2018</li>
			<li>[2018.08]  &nbsp;&bull;&nbsp; First Place in Pro. SimuroSot-Miro Middle at 23rd FIRA RobotWorld Cup 2018</li>
			<li>[2018.08]  &nbsp;&bull;&nbsp; First Place in Pro. SimuroSot (5 vs. 5) at 18th National Robot Championship and 9th International Humanoid Robot Olympic Competition 2018</li>
			<li>[2018.09]  &nbsp;&bull;&nbsp; University Undergraduate Fellowship, Northwestern Polytechnical University</li>
			<li>[2017.09]  &nbsp;&bull;&nbsp; University Undergraduate Fellowship, Northwestern Polytechnical University</li>
		</ul>

	<h2><strong>Reviews</strong></h2>
	    <ul>
		<h5><li>Conference Review</li></h5>
		    <ul>
			<li>MICCAI 2023, MICCAI 2024, MICCAI 2025</li>
			<li>PRCV 2023</li>
			</ul>
		<h5><li>Journal Review</li></h5>
		    <ul>
			<li>IEEE-TMI/TNNLS/JBHI</li>
			<li>AAS-CN (ACTA AUTOMATICA SINICA)</li>
			<li>BSPC</li>
			</ul>
		</ul>

	<h2><strong>Academic Activities</strong></h2>
	<ul>
		<li>8-12 October 2023: DALI@MICCAI 2023, Vancouver, Canada <strong><i>(Oral)</i></strong></li>
		<li>8-12 October 2023: MICCAI 2023, Vancouver, Canada <strong><i>(Poster)</i></strong></li>
		<li>22-24 August 2022: VALSE 2022, Tianjin, China <strong><i>(Poster)</i></strong></li>
		<li>11-13 August 2022: MICS 2022, Nanjing, China <strong><i>(Student Challenge Presentation)</i></strong></li>
		<li>25-26 October 2021: MAI workshop 2021, Online <strong><i>(Oral)</i></strong></li>
    </ul>

	<p>
		<center>
<!--			<td><div id="clustrmaps-widget" style="width:40%">-->
<!--			<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=3oEqJsYfiOcdbboZSNw7vF51Tg07i-AMnmtYt_vxKlU&cl=ffffff&w=a"></script>-->
<!--			</div></td>-->
			&copy; Zehui Liao | Last updated: 26 June 2025
				<div class="text">
                    <b>Acknowledgement:</b> This page is based on <a href="https://ycwu1997.github.io/eli/">this template</a>
                    by <a href="https://github.com/ycwu1997"> Yicheng Wu </a>
                </div>
		</center>
	</p>
</div>
</div>
</body></html>
